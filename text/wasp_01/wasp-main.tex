\newif\ifTLP     \TLPtrue
\newif\ifTLPBIB  %\BIBTLPtrue
\newif\ifLNCS	%\LNCStrue
\newif\ifExamples%\EXAMPLEStrue
\newif\ifREVEDIT\REVEDITtrue


% TPLP/LNCS stuff

\ifTLP
  \documentclass[x11names]{tlp} 
  \renewcommand{\cite}{\citep}
  \fi
\ifLNCS
  \documentclass[runningheads,x11names]{llncs}\fi

\ifTLP
  \usepackage{multirow}
\fi

\input{macros}

\ifREVEDIT
	\usepackage{geometry}
	\geometry{
		paper=a4paper,
		left=0.5cm,
		width=14cm,
		marginparwidth=5.5cm,
		top=1cm,
		bottom=2cm
	}
\fi

\begin{document}

%   PREAMBLE / METADATA

\title{%
	An Algebraic Approach to Weighted
	Answer~Set~Programming
}
\ifTLP
	\lefttitle{F.~Coelho, B.~Dinis, D.~Seipel and S.~Abreu}

	\begin{authgrp}
		\author{\sn{Francisco} \gn{Coelho}}
		\affiliation{NOVA-LINCS, University of \'Evora}
		\email{fc@uevora.pt}

		\author{\sn{Bruno} \gn{Dinis}}
		\affiliation{CIMA, University of \'Evora}
		\email{bruno.dinis@uevora.pt}

		\author{\sn{Dietmar} \gn{Seipel}}
		\affiliation{Universit\"at W\"urzburg}
		\email{dietmar.seipel@uni-wuerzburg.de}

		\author{\sn{Salvador} \gn{Abreu}}
		\affiliation{NOVA-LINCS, University of \'Evora}
		\email{spa@uevora.pt}
	\end{authgrp}
\else
	\author{%
		Francisco Coelho\inst{1,2}   \and %
		Bruno Dinis\inst{1,3}        \and %
		Dietmar Seipel\inst{4}       \and %
		Salvador Abreu\inst{1,2}     %
	}
	\institute{%
		University of Ã‰vora%
		\\
		\email{\{fc,bruno.dinis,spa\}@uevora.pt} \and
		NOVA LINCS \and
		CIMA \and
		Universit\"at W\"urzburg%
		\\
		\email{dietmar.seipel@uni-wuerzburg.de}
	}
\fi

\maketitle

\begin{abstract}
	% \spa{needs work} %
	\Aclp{LP}, more specifically, \aclp*{ASP}, can be annotated with probabilities on facts to express uncertainty.
	We address the 	problem of propagating weight annotations on facts (\eg\ probabilities) of an \acl*{ASP} to its \aclp*{SM}, and from there to events (defined as sets of atoms) in a dataset over the program's domain. %

	We propose a novel approach which is algebraic in the sense that it relies on an equivalence relation over the set of events.
	Uncertainty is then described as polynomial expressions over variables.
	We propagate the weight function in the space of models and events, rather than doing so within the syntax of the program.
	%
	Our approach allows us to investigate weight annotated programs and to determine how suitable a given one is for modeling a given dataset containing events.
\end{abstract}

\begin{keywords}
	Answer-Set Programming, Stable Models, Probabilistic Logic Programming
\end{keywords}

\section{Introduction}
\label{sec:introduction}

\topicnote{logic+uncertainty}\noindent Using \iac{LP} to model and reason over a real world scenario is often difficult because of uncertainty underlying the problem being worked on.
Classic \acp{LP} represent knowledge in precise and complete terms, which turns out to be problematic when the scenario is characterized by stochastic or observability factors.\sidenote{insert simple, nice example}
%
% Medical exams illustrate both problems: some parts of a living organism can't be directly observed \ie\ a system with unreachable parts; instrumentation has limits and imperfections \ie\ sensors that add noise to the real values.
%
We aim to explore how \acp{ASP} plus weight annotated facts can lead to useful characterizations for this class of problems.

To setup a working framework, we make the following assumption:
\begin{assumption}[System Representation, Data and Propagation]\label{asp:system.representation.data}
	Consider a \emph{system} whose states are \emph{partially observable} (\ie, observations can miss some state information) or \emph{stochastic} (\ie\ reported values are affected by random noise).
	We assume that knowledge about such \emph{system} features a formal specification including \emph{weighted facts} and empirical \emph{data} such that:
	\begin{description}\tight
		\item[(Representation)]
		\topicnote{system = representation, \acs*{SM}=state}
		The system has a formal \emph{representation}\footnote{We use `representation' instead of `model' to avoid confusion with the \emph{stable models} of \aclp{ASP}.} in the form of a special \acl{LP};
		The program's \aclp*{SM} correspond one-to-one with the system states.
		\item[(Data)] \emph{Data} is a set of observations; a single \emph{observation} (of the system states) results from a set of (boolean) \emph{sensors}.
		\item[(Propagation)]
		\topicnote{weight propagation}
		The \emph{weights} in \emph{facts} are \emph{propagated} to the \aclp{SM} of the representation.
	\end{description}
\end{assumption}

\topicnote{parameter estimation}
In this setting, data from observations can be used to estimate some parameteres used in the propagation process and, more importantly, to address the question of `\emph{How accurate is the representation of the system?}'.%


%
\topicnote{other \acs*{PLP}}%
Other \ac{PLP} systems such as \texttt{Problog}~\cite{de2007problog}, \texttt{P-log}~\cite{baral2009probabilistic} or \lpmln~\cite{lee2016weighted}, in line with~\cite{kifer1992theory}, derive a probability distribution of the \aclp{SM} from the \textit{syntax} of an annotated logic program.  The more expressive of these systems, according to \cite{lee2017lpmln}, is \lpmln, that can embed the\ac{MAP} estimation of the other systems.
%
\topicnote{probability from syntax}%
Since in these \ac{PLP} systems the probability distribution results from the program's syntax, these systems are limited to handle \emph{a priori} information and are unable to support \emph{posterior} data. Furthermore, these distributions are limited to the \acp{SM}, while we \emph{extend their domain to any event} (\ie\ any set of atoms). 

However, the key feature that we aim to address is concerned with the inherent uncertainty of the \acp{SM} in \aclp{LP} such as $\weightfact{a}{0.3}, b \vee c \clause a$. Intuitively, this program entails three \acp{SM}: $ac$, $ab$ and $\neg a$. We can, for example, assign the probability of $\neg a$ as $0.7$ but what about $ab$ and $ac$? Systems like \lpmln\ assign the same probability to these \acp{SM} \cite{lee2017lpmln,cozman2020joy}.

\sidenote{\franc{addressing} It is not made sufficiently clear why we need another probabilistic formalism based on answer set programming, or why this particular formalisms should fill that niche.}%
We question the underlying assumption of such assignments and propose a method where the distribution that results from the representation includes parameters (\ie\ variables in the algebraic sense: symbols for unknown quantities) that express the lack of \emph{prior} information concerning cases as above. The values of these parameters can be estimated \emph{a posteriori}, in the presence of data.

\sidenote{\franc{addressing} hidden values and default negation.}
To frame this setting we extend our assumptions:
\begin{assumption}[Sensor Representation and Events]\label{asp:sensor.representation.events}
	\begin{description}\tight
		\item[(Sensors)] \topicnote{sensor = atom}The \emph{sensors} of the system's states are associated to some atoms in the representation; 
		\item[(Events)] \topicnote{event = atoms}An \emph{event} is a set of atoms from the representation.\sidenote{reconsider: is this a definition?}
	\end{description}
\end{assumption}

\topicnote{strong + week negation}More specifically, following the terminology set in \cite{calimeri2020aspcore}, a sensor $\sigma_a$ can `activate' the associated (\emph{classical}, \emph{strong}) \emph{atom} $a$ whereas no activation is represented by the (\emph{default}, \emph{weak} or \emph{negation-as-failure (naf)}) \emph{literal} $\naf a$. The same applies to a sensor $\sigma_{\neg a}$ associated to the (classically) negated atom $\neg a$.

%
\topicnote{hidden + stochastic}\Cref{asp:sensor.representation.events} enables a straightforward representation of \emph{hidden} parts of a system as well as faulty (\emph{stochastic}) sensors. For example, in the event
\begin{equation}
	\left\{ a, \neg a, \naf b, \naf \neg b, \naf c, \neg c \right\}\label{eq:example.event.long}	
\end{equation}
both $a$ and $\neg a$ are activated (suggesting \eg\ a problem in the associated sensors), $b$ is not observed (\ie\ hidden), and $\naf c, \neg c$ reports the (consistent) activation of $\neg c$ and no activation of $c$.
\topicnote{event $>$ observation} 
While every observation is an event, since some events can contain atoms not associated to sensors, not all events are observations. Furthermore, some events coincide with a \acl{SM} but others don't; an event may not uniquely determine a state of the system --- how to associate events to \aclp*{SM} and, thus, to system states, is addressed in \cref{sec:propagating.weights}.


\topicnote{event short notation}If we (i) omit the naf-literals; (ii) use $\co{x}$ to denote the classical $\neg x$; (iii) and use expressions like $ab$ to denote sets of literals such as $\set{a, b}$, then the event in (\ref{eq:example.event.long}) can be shortened to the equivalent form
\begin{equation}	
	a\co{a}\co{c}.\label{eq:example.event.short}
\end{equation}
%
Here we follow the convention, from \cite{gelfond1988stable}, of denoting a model by the set of true atoms, stressing that `\emph{falsehood}' results only from the default negation \ie\ $\naf a$ (\ie\ `\texttt{not a}' or `\texttt{\textbackslash+ a}' in logic languages).
More precisely, a model denotation can contain atoms such as $a$ or $\co{b}$ but not literals $\naf a, \naf \co{b}$. 
%
Our choice to represent sensor input using both positive and negative atoms is based on the following points: 
(i) it can be the case that there are two different sensors, $\sigma_a$ for the `positive' values and $\sigma_{\co{a}}$ for the `negative' ones;
(ii) the case where a single sensor $\sigma_{\hat{a}}$ always yields either `positive' or `negative' values can be represented by the rule $a \vee \neg a$; also, 
(iii) a closed-world assumption, where absence of sensor output means (classical) negation, can be represented by the rules $\co{a} \clause \naf a, a \clause \naf \co{a}$. 

\topicnote{weights + probabilities}%
Like in \lpmln, we annotate facts (\ie\ atoms) with weights \cite{lee2017lpmln} instead of probabilities, that result from normalization of the former.
\topicnote{propagation}
By \emph{propagation} we mean the use of those weights to define a `weight' function on the \aclp{SM} and then extended it to all the events in the program domain.
\topicnote{\acp{SM} + non-unique/non-deterministic}%
The step from facts to \acp{SM} is non-deterministic in the sense that a given set of facts may entail zero, one or more \acp{SM} (see \cref{ex:fruitful}).
This is a well-known situation, explained in \cref{sec:syntax.and.semantics} and also in \cite{verreet2022inference,pajunen2021solution,cozman2020joy,baral2009probabilistic}, when propagating weights to \aclp{SM}: \emph{How to distribute the weight of a fact to all the entailed \acp{SM}?}
\topicnote{parameters}
We represent non-unique choices by parameters that can be later estimated from further information, \ie\ data.
This approach enables later refinement from additional evidence and also scoring a program  w.r.t.\ the available data.
%

\topicnote{\acp*{ASP}}
\Acfp{ASP} are logic programs based on the \acl{SM} semantics of \acp{NP} \cite{lifschitz2002answer,lifschitz2008twelve}. 
\Acp{ASP} represent a problem and the resulting models (\emph{answer sets}) can be found using different approaches, including SAT solving technology \cite{gebser2011potassco,adrian2018asp,niemela1997smodels} or through top-down search \cite{alberti2017cplint,arias2020justifications,marple2017computing}.
% Unlike \texttt{Prolog}, \ac{ASP} is a truly declarative language that
% supports language constructs such as disjunction in the head of a
% rule, choice rules, and both hard and weak constraints.

\topicnote{\acs*{DS}}
The \ac{DS} \cite{sato1995statistical,riguzzi2022foundations} is the base for \acf{PLP}, to extend \aclp{LP} with probabilistic reasoning.
%
%
\sidenote{\franc{addressing} better examples that show the real usefulness of this approach \franc{ \eg\ a toy problem with a biased coin; also see the examples on the other systems.}}%
We are particularly interested in the following setting and application scenarios of such an extension to logic programs:
\begin{description}
	\item[Partial Observability] \topicnote{partial observability}A system's state can have \emph{hidden variables}, not reported by the sensors. 
	\item[Sensor Error] \topicnote{sensor error}Information gathered from the sensors can carry \emph{stochastic perturbations}.
	\item[Representation Induction] \topicnote{representation induction}Combine representations with data to induce \emph{more accurate representations}.
	\item[Probabilistic Tasks] \topicnote{probabilistic tasks}Support common probabilistic tasks such as \acf{MAP}, \ac{MLE} and \ac{BI} on the \emph{representation domain} \ie\ the set of all events.
\end{description}

\noindent The remainder of this article is structured as follows: \cref{sec:framework} provides necessary context.
In \cref{sec:syntax.and.semantics} we discuss the syntax and semantics of our proposed language for \acfp{WASP}.
We also define a weight function over total choices and address the issue of how to propagate these probabilities from facts to events, in \cref{sec:propagating.weights}.
This method relies on an equivalence relation on the set of events.
Furthermore, we express uncertainty by polynomial expressions over variables which depend on the total choices and on the stable models. By then the \emph{Partial Observability} and \emph{Sensor Error} points are addressed.
Some final remarks and ideas for future developments including \emph{Representation Induction} and \emph{Probabilistic Tasks} are presented in \cref{sec:discussion}.

\section{Framework}
\label{sec:framework}

\topicnote{\ac*{WASP}}%
We start by refining \cref{asp:system.representation.data,asp:sensor.representation.events} to set `representation' as an `\ac{ASP} with weights':
\begin{assumption}[Representation by \Aclp*{ASP} with Weigths]\label{asp:wasp.represent.systems}
	\begin{description}
		\item[(\Aclp*{ASP} and Weights)] A \emph{representation} of a system is an \emph{\acl{ASP} }that includes \emph{weighted facts}.
	\end{description}
	%
	\topicnote{\acl*{WF}}
	A \emph{\acf{WF}} or an \emph{annotated fact} has the from `$\weightfact{a}{w}$' where $a$ is an atom, $w \in \intcc{0, 1}$, and defines the disjunctive fact $a \vee \co{a}$. A model will include either $a$ or $\co{a}$ but never both.	
\end{assumption}

\topicnote{\acl*{TC}}
Selecting one of $a, \co{a}$ for each \ac{WF} in a program will lead to a \emph{\acf{TC}}
\footnote{We use the term `choice' for historical reasons, \eg\ see \cite{cozman2020joy} even though not related to the usual `choice' elements, atoms or rules from \eg\ \cite{calimeri2020aspcore}.}.
\topicnote{propagating}
Propagating weights from \acp{WF} to \acp{TC} is relatively straightforward (see \cref{eq:weight.total.choice}) but propagation  to events requires a step trough the program's \aclp*{SM},  addressed in \cref{sec:propagating.weights}. 

\paragraph{About Propagating Weights from \Aclp{TC}.}%

\topicnote{propagation + non-unique/non-deterministic}
Our goal to propagate weights from \acp{TC} to \acp{SM} and from there to any event soon faces a non-deterministic problem, illustrated by the program $\SBF$ in \cref{ex:fruitful}, \cref{ssec:propagating.weights}, where multiple \acp{SM}, $ab$ and $ac$, result from a single \ac{TC}, $a$, but \emph{there is not enough information in the representation to assign a single weight to each one of those \acp{SM}}.
In \cref{subsec:from.tchoices.to.events} we use algebraic variables\footnote{We explicitly write `algebraic' variables to avoid confusion with logic variables.} to describe the lack of information in a representation in order to deterministically propagate the weight to the \aclp{SM} and events.
The values of those variables can be estimated from available data, a contribute to the \emph{Representation Induction} application goal, set in \cref{sec:introduction}.

The lack of a unique \acl{SM} from a \acl{TC} is also addressed in~\cite{cozman2020joy} along an approach using credal sets.
In another related work~\cite{verreet2022inference}, epistemic uncertainty (or model uncertainty) is considered as lack of knowledge about the underlying model, that may be mitigated via further observations.
This seems to presuppose a bayesian approach to imperfect knowledge in the sense that having further observations allows one to improve or correct the model.
Indeed, that approach uses Beta distributions on the total choices in order to be able to learn a distribution on the events.
This approach seems to be specially fitted to being able to tell when some weight lies beneath some given value.
Our approach is similar in spirit, while remaining algebraic in the way the propagation of weights is addressed.

\section{Syntax and Semantics of Weighted ASP}
\label{sec:syntax.and.semantics}

We start the formal definition of \emph{\acl*{WASP}} with the setup and discussion of a minimal syntax and semantics of propositional \ac{ASP}, without variables, functors or relation symbols, but enough to illustrate our method to propagate weights from annotated facts to events. From now on `$\neg x$' and `$\co{x}$' denote classical negation and `$\naf x$' default negation.

\paragraph{Syntax.}
\label{par:syntax}

We slightly adapt \cite{calimeri2020aspcore}. Let $\ATOMSset$ be a finite set of symbols, the \emph{positive atoms}. 
For $a \in \ATOMSset$, the expressions $a$ and $\neg a$ (the later a \emph{negative atom}, also denoted $\co{a}$) are \emph{(classical) atoms}.
\defnote{atom}
If $a$ is an atom, the expressions $a$ and $\naf a$ are \emph{(naf-)literals}.
\defnote{literal}
%
A \textit{rule} is of the form
\defnote{rule}
$$
h_1 \disj \cdots \disj h_n \clause 
	b_1 \conj \cdots \conj b_m
$$
where the $h_i$ are atoms and the $b_j$ are literals. 
The symbol `$\clause$' separates the \textit{head} from the \textit{body}. 
\defnote{head;body}
A rule is a \emph{constraint}\footnote{An `\emph{integrity constraint}' in \cite{calimeri2020aspcore}.} if $n = 0$, \emph{normal} if $n = 1$, \emph{disjunctive} if $n > 1$, and a \emph{fact} if $m = 0$.
\defnote{constraint;normal;disjunctive;fact}

An \textit{\acf{ASP}} is a set $P$ of facts and rules, denoted, resp. $\FACTSset\at{P}$ and $\RULESset\at{P}$, or simply $\FACTSset$ and $\RULESset$.
\defnote{program}
In a \textit{normal program} all the rules are normal.
Notice that programs with constraint or disjunctive rules can be converted into normal programs \cite{gebser2022answer}.

\paragraph{Semantics.}

The standard semantics of an \ac{ASP} has a few different, but equivalent, definitions \cite{lifschitz2008twelve}.
A common definition is as follows \cite{gelfond1988stable}: let $P$ be a \acl{NP}.
The Gelfond/Lifschitz \emph{reduct} of $P$ relative to the set $X$ of atoms results from (i) deleting rules that contain a literal of the form $\naf p$ in the body with $p \in X$ and then (ii) deleting the remaining literals of the form $\naf q$ from the bodies of the remaining rules.
\defnote{reduct}
Now, $M$ is a \textit{\acf{SM}} of $P$ if it is the minimal model of the reduct of $P$ relative to $M$.
\defnote{\acl{SM}}
We denote by $\MODELset\at{P}$, or simply $\MODELset$, the set of \aclp{SM} of the program~$P$.

\paragraph{Evaluation without Grounding.}

While the most common form to generate \aclp{SM} is based on \emph{grounding}, a different approach is the one supported by \texttt{s(CASP)}, a system that can evaluate \ac{ASP} programs with function symbols (functors) and constraints without grounding them either before or during execution, using a method similar to SLD resolution~\cite{marple2017computing,arias2020justifications}.
%
\sidenote{Improve grounding and propositional cases.}
%
This enables the generation of human readable explanations of the results of programs and addresses two major issues of grounding-based solvers, that 
(i) either do not support function symbols or, using finite domains, lead to exponential groundings of a program and 
(ii) compute the complete model of the grounded program when, in some scenarios, it is desirable to compute only a partial stable model containing a query.%%

\subsection*{\acsp{WASP} and their Derived Programs}

\emph{\Acfp{WASP}} extend \acp{ASP} by adding facts with weight annotations, \ie\ \emph{\acfp{WF}}.
\defnote{\acl{WF}}
%
Notice that we have $w\in \intcc{0,1}$ but $w$ is not interpreted as a probability but, instead, as a \emph{balance} between the \emph{choices} $a$ and $\co{a}$.

We denote the set of \aclp{WF} of a program by $\WEIGHTFset$, and $\WATOMset$ the set of positive atoms in $\WEIGHTFset$.

Our definition of \acp{WASP} is restricted because our goal is to illustrate the core of a method to propagate weights from \aclp{TC} to events.
Our programs do not feature logical variables, relation symbols, functors or other elements common in standard \ac{ASP}.
Also, weight annotations are not associated to (general) rule heads or disjunctions.
However, these last two restrictions do not reduce the expressive capacity of the language because, for the former, a rule with an annotated head can be rewritten as:
% such as $ \weightrule{\alpha}{p}{\beta} $
\begin{equation*}
	\weightrule{\alpha}{w}{\beta} \qquad \Longrightarrow \qquad
	\left\{
		\begin{aligned}
		\weightfact{\gamma & }{w},                       %
		\\
		\alpha           & \clause \beta \wedge \gamma
	\end{aligned}
	\right.
\end{equation*}
while annotated disjunctive facts
% , such as $ \weightfact{\alpha \vee \beta}{p} $, can be translated as follows:
\begin{equation*}
	\weightfact{\alpha \vee \beta}{w} \qquad \Longrightarrow \qquad
	\left\{
	\begin{aligned}
		\weightfact{\gamma  & }{w},           %
		\\
		\alpha \vee \beta & \clause \gamma,           %
		\\
		\co{\alpha}& \clause \co{\gamma},  &&
		\co{\beta}& \clause \co{\gamma}.
	\end{aligned}
	\right.
\end{equation*}

\paragraph{Derived Program.}

The \emph{derived program} of a \ac{WASP} is the \ac{ASP} obtained by replacing each \acl{WF} $\weightfact{a}{w}$ by a disjunction $a \disj \co{a}$.
\defnote{derived}
The \textit{\aclp{SM}} of a \acs{WASP} program are the \aclp{SM} of its derived program.
So, we also denote the set of \acp{SM} of a (derived or) \acs{WASP} program $P$ by $\MODELset\at{P}$ or $\MODELset$.

\paragraph{Events.}

An \emph{event} of a program $P$ is a set of atoms from $P$.
\defnote{event}
We denote the set of events by
$\EVENTSset\at{P}$ or simply $\EVENTSset$.
An event $e \in \EVENTSset$ which includes a set $\set{x, \co{x}}$ is said to be \textit{inconsistent}; otherwise it is \textit{consistent}.
\defnote{(in)consistent}
The set of consistent events is denoted by $\CONSISTset$.

%\ifExamples
\begin{example}
	\label{ex:fruitful}\em

	Consider the following \acl{WASP} :
	\begin{equation}\label{eq:fruitful}
		\SBF = \left\{\begin{split}
			\weightfact{a & }{0.3},   %
			\\
			b \vee c    & \clause a
		\end{split}
		\right.
	\end{equation}
	which has the set $\WEIGHTFset = \{ a:0.3 \}$ of \aclp{WF}.
This program is transformed into the \acl{ASP}
	\begin{equation}\label{eq:derived.fruitful}
		\SBF' = \left\{\begin{split}
			a \vee \co{a} & ,          %
			\\
			b \vee c      & \clause a,
		\end{split}
		\right.
	\end{equation}
	with the set
	$ \MODELset = \{\, \co{a}, ab, ac\, \} $
	of stable models.

The atoms of these programs are 
\begin{equation}
	\ATOMSset = \set{a, \co{a}, b, \co{b}, c, \co{c}}
	\label{eq:atoms.fruitful}
\end{equation}
and the events are%
\footnote{$\powerset{X}$ is the \emph{power set} of $X$: $A \in \powerset{X} \Leftrightarrow A \subseteq X$.} 
\begin{equation}
	\EVENTSset = \powerset{\ATOMSset}.
	\label{eq:fruitful.events}
\end{equation}
\end{example}

\subsection*{Total Choices and their Weights}
\label{ssec:totalchoices.weights}

A disjunctive head $a \disj \co{a}$ in the derived program represents a single \textit{choice}, either $a$ or $\co{a}$.
\defnote{\acl{TC}}
A \textit{\acl{TC}} of the derived program, and of the \ac{WASP} program, is $t = \set{\hat{a} \given \weightfact{a}{p} \in \WEIGHTFset}$ where each $\hat{a}$ is either $a$ or $\co{a}$.
We denote by $\TCHOICEset$ the set of total choices of a \ac{WASP} or of its derived program.

\ifExamples
	\begin{example}[\Aclp{PF} and \aclp{TC}.]
		\label{ex:total.choices}\em

		Consider the program $B$ defined by
		\begin{equation*}
			\begin{split}
				\weightfact{a & }{0.3},             %
				\\
				\weightfact{b & }{0.6},             %
				\\
				c           & \clause a \wedge b.
			\end{split}\label{eq:total.choices}
		\end{equation*}

		The weighted facts of $B$ are
		\[ \WEIGHTFset_{B} = \set{~\weightfact{a}{0.3}, \weightfact{b}{0.6}~}, \]
		and the total choices are
		\begin{equation*}
			\TCHOICEset_{B} = \set[2]{\:
				\set[1]{a, b},
				\set[1]{a, \co{b}},
				\set[1]{\co{a}, b},
				\set[1]{\co{a}, \co{b}}\: }.
		\end{equation*}

		\emph{E.g.}, the total choice $\set{\co{a}, b} $ results from choosing $\hat{a} = \co{a}$ from the weighted fact $\weightfact{a}{0.3}$ and $\hat{b} = b$ from  $\weightfact{b}{0.6}, $ while $\set{a, b} $ results from choosing $\hat{a} = a$ from $\weightfact{a}{0.3}$ and $\hat{b} = b$ from $\weightfact{b}{0.6}$.

	\end{example}
\fi

The \emph{weight of the \acl{TC} $t \in \TCHOICEset$} is given by the product
\defnote{$\wgtT$}
\begin{equation}
	\wgtT\at{t} =
	\prod_{\substack{
			\weightfact{a}{w}~ \in ~\WEIGHTFset,%
	\\
			a~ \in~ t}} w\quad \times\quad
	\prod_{\substack{
			\weightfact{a}{w}~ \in ~\WEIGHTFset,%
	\\
			\co{a}~\in~ t}} \co{w}.
	\label{eq:weight.total.choice}
\end{equation}

Here $\co{w} = 1 - w$, and we use the subscript in $\wgtT$ to explicitly state that this function concerns total choices.
Later we'll use subscripts $\MODELset, \EVENTSset$ to deal with weight functions of \aclp{SM} and events, $\wgtM, \wgtE$.

\ifExamples
	\begin{example}[Weights for \aclp{TC}]%
		\label{ex:weight.total.choices}
		\em

		Continuing with the program from \cref{ex:total.choices}, the weights of the \aclp{TC} are:
		\begin{equation*}
			\begin{aligned}
				\wgtT\at{\set[1]{a, b}}           & = 0.3 \times 0.6           &                  & = 0.18, %
				\\
				\wgtT\at{\set[1]{a, \co{b}}}      & = 0.3 \times \co{0.6}      & = 0.3 \times 0.4 & = 0.12, %
				\\
				\wgtT\at{\set[1]{\co{a}, b}}      & = \co{0.3} \times 0.6      & = 0.7 \times 0.6 & = 0.42, %
				\\
				\wgtT\at{\set[1]{\co{a}, \co{b}}} & = \co{0.3} \times \co{0.6} & = 0.7 \times 0.4 & = 0.28.
			\end{aligned}
		\end{equation*}

		Suppose that in this program we change the weight in $\weightfact{b}{0.6}$
		to $\weightfact{b}{1.0}$.
		Then the \aclp{TC} are the same but the weights become
		\begin{equation*}
			\begin{aligned}
				\wgtT\at{\set[1]{a, b}}           & = 0.3 \times 1.0           &                  & = 0.3, %
				\\
				\wgtT\at{\set[1]{a, \co{b}}}      & = 0.3 \times \co{1.0}      & = 0.3 \times 0.0 & = 0.0, %
				\\
				\wgtT\at{\set[1]{\co{a}, b}}      & = \co{0.3} \times 1.0      & = 0.7 \times 1.0 & = 0.7, %
				\\
				\wgtT\at{\set[1]{\co{a}, \co{b}}} & = \co{0.3} \times \co{1.0} & = 0.7 \times 0.0 & = 0.0.
			\end{aligned}
		\end{equation*}
		which, as expected from stating that $\weightfact{b}{1.0}$, is like having $b$ as a (deterministic) fact:
		\begin{equation*}
			\begin{split}
				\weightfact{a & }{0.3},             %
				\\
				b           & ,                   %
				\\
				c           & \clause a \wedge b.
			\end{split}
		\end{equation*}

		This will also be stated in \cref{prop:prob.one}, when the proper definitions
		are set.
	\end{example}
\fi Some \aclp{SM} are entailed from some \aclp{TC} while other \acp{SM} are entailed by other \acp{TC}.
We write $\tcgen{t}$ to represent the set of \aclp{SM} entailed by the \acl{TC} $t \in \TCHOICEset$.

\ifExamples
	\begin{example}[\Aclp{SM} and \aclp{TC}.]%
		\em

		Continuing \cref{ex:fruitful}, the \acl{TC} $t = \set{\co{a}}$ entails a
		single \acl{SM}, $\co{a}$, so $ \MODELset\at{\set{\co{a}}} = \set{\co{a}} $
		and, for $t = \set{a}$, the program has two \aclp{SM}: $
			\MODELset\at{\set{a}} = \set{ab, ac}$.
		\begin{equation*}
			\begin{array}{l|r}
				t \in \TCHOICEset   & \MODELset\at{t} %
				\\
				\hline \set{\co{a}} & \co{a}          %
				\\
				\set{a}             & ab, ac
			\end{array}
		\end{equation*}

		The second case illustrates that propagating weights from \aclp{TC} to
		\aclp{SM} entails a non-deterministic step: \textit{How to propagate the
			weight $\wgtT\at{\set{a}}$ to each one of the \aclp{SM} $ab$ and $ac$?}
	\end{example}
\fi

Our goal can now be rephrased as to know how to propagate the weights of the program's \aclp{TC}, $\wgtT$, in \cref{eq:weight.total.choice}
%(which is, indeed, a product of Bernoulli distributions \cite{Teugels90}), 
to the program's events, $\wgtE$ to be defined later, in \cref{eq:weight.events,eq:weight.events.unconditional}.



\paragraph{Propagation of Weights.}

As a first step to propagate weight from \aclp{TC} to events, consider the $\SBF$ program of \cref{eq:fruitful} and a possible propagation of $\wgtT:\TCHOICEset \to \intcc{0,1}$ from \aclp{TC} to the \aclp{SM}, $\wgtM:\MODELset \to \intcc{0,1}$ (still informal, see \cref{eq:weight.stablemodel}).
%
\sidenote{\franc{addressing} Definition of \TCHOICEset?}
%
It might seem straightforward, in \cref{ex:fruitful}, to set $\wgtM\at{\co{a}}=0.7$ but there is no explicit way to assign values to $\wgtM\at{ab}$ and $\wgtM\at{ac}$.
We represent this non-determinist by a parameter $\theta$ as in
\begin{equation}
	\begin{aligned}
		\wgtM\at{ab} & = 0.3\, \theta,
		\\
		\wgtM\at{ac} & = 0.3\, (1 - \theta)
	\end{aligned}\label{eq:theta.and.stablemodels}
\end{equation}
to express our knowledge that $ab$ and $ac$ are models entailed from a specific choice and, simultaneously, the inherent non-determinism of that entailment.
In general, it might be necessary to have several such parameters, each associated to a given \acl{SM} $s$ (in \cref{eq:theta.and.stablemodels}, $s = ab$ in the first line and $s = ac$ in the second line) and a \acl{TC} $t$ ($t=a$ above), so we write $\theta_{s,t}$.
Obviously, for reasonable $\theta_{s,t}$, the total choice $t$ must be a subset of the stable model $s$.

Unless we introduce some bias, such as $\theta = 0.5$ as in \lpmln\ \cite{lee2016weighted}, the value for $\theta_{s,t}$ can't be determined just with the information given in the program. But it might be estimated with the help of further information, such as an empirical distribution from a dataset.
Further discussion of this point is outside the scope of this paper.
%

Now consider the program
\begin{equation}\label{eq:single}
	\left\{\begin{split}
		\weightfact{a & }{0.3},   %
		\\
		b & \clause a \wedge \naf b
	\end{split}
	\right.
\end{equation}
that has a single \ac{SM}, $\co{a}$. Since the weights are not interpreted as probabilities, there is no need to have the sum on the \aclp{SM} equal to $1$. So the weights in the \acp{TC} of \cref{eq:single} only set
$$
\wgtM\at{\co{a}} = 0.7.
$$
In this case, if we were to derive a probability of the \acp{SM}, normalization would give $\pr{\co{a}} = 1.0$.
\sidenote{\franc{addressing} Explain what appens with $a \vee \neg a, b \clause a \wedge \naf b$ that has only the stable model $\neg a$. \franc{by stressing \textbf{weights} instead of probabilities.}}

Also facts without annotations can be transformed into facts with weight $1$:
\begin{equation}
	a \qquad \Longrightarrow \qquad \weightfact{a}{1.0}. \label{eq:noannotation}
\end{equation}

\topicnote{propagation, semantics}
The method that we are proposing does not follow the framework of~\cite{kifer1992theory} and others, where the syntax of the program determines the propagation from probabilities explicitly set either in facts or other elements of the program.
Our approach requires that we consider the semantics, \emph{i.e.}\ the \aclp{SM} of the program, independently of the syntax that provided them. From there we propagate weights to the program's events and then, if required, normalization provides the final probabilities.
Moreover, we allow the occurrence of variables in the weights, in order to deal with the non-determinism that results from the non-uniqueness of \acp{SM} entailed from a single \ac{TC}.
These variables can be later estimated from available data.%

\ifExamples
	\begin{example}[No Syntax Propagation.]
		\label{example:not.syntax.propagation}
		\em

		Consider the program
		\begin{equation*}
			\begin{split}
				\weightfact{a & }{0.3},   %
				\\
				b           & \clause a
			\end{split}
		\end{equation*}

		We don't follow the clause $b \clause a$ to attribute a weight to $b$.
		Instead, that will result from considering how events are related with the
		\aclp{SM} and these with the \aclp{TC}.		
		If one follows the steps of
		\cref{sec:propagating.weights} would get
		\begin{equation*}
			\begin{split}
				\wgtE\at{a}      & = \wgtE\at{b} = \wgtE\at{ab} = 0.05,                          %
				\\
				\wgtE\at{\co{a}} & = \wgtE\at{\co{a} b} = \wgtE\at{\co{a}\co{b}} = \frac{7}{60}, %
				\\
				\wgtE\at{\set{}} & = 0.5.                                                      %
				\\
			\end{split}
		\end{equation*}

	\end{example}
\fi

\ifExamples
	\begin{example}[Events of the fruitful \ac{WASP}.]\label{ex:events}\em

		The atoms of program \cref{eq:fruitful} are $\ATOMSset = \set{a, b, c}$ and
		the literals are
		\begin{equation*}
			\LITERALSset = \set{\, \co{a}, \co{b}, \co{c}, a, b, c\, }.
		\end{equation*}

		In this case, $\EVENTSset$ has $2^6 = 64$ elements.
Some, such as
		$\set{\co{a}, a, b}$, contain an atom and its negation ($a$ and $\co{a}$ in
		that case) and are inconsistent.
The set of atoms $\ATOMSset = \set{a, b, c}$
		above generates $37$ inconsistent events and $27$ consistent events.
Notice
		that the empty set is an event, that we denote by \emptyevent.

		As above, to simplify notation we write events as $\co{a}ab$ instead of
		$\set{\co{a}, a, b}$.
	\end{example}
\fi

\subsection*{Related Approaches and Systems}
\label{ssec:other.approaches}

The core problem of setting a semantics for probabilistic logic programs, the propagation of probabilities from \aclp{TC} to \aclp{SM} in the case of \ac{ASP} or to other types in other logic programming systems (\eg\ to possible worlds in \texttt{Problog}) has been studied for some time~\cite{kifer1992theory,sato1995statistical}.

For example, the \emph{credal set} approach of~\cite{cozman2020joy}, defines $\prT$ in a way similar to \cref{eq:weight.total.choice} but then, for $a \in \ATOMSset, t \in \TCHOICEset$, the probability $\pr{a \given t}$ is unknown but bounded by $\underbar{\prfunc}\at{a \given t}$ and $\overline{\prfunc}\at{a \given t}$, that can be explicitly estimated from the program.

\texttt{Problog} \cite{fierens2015inference,verreet2022inference} extends \texttt{Prolog} with probabilistic facts so that a program specifies a probability distribution over possible worlds.
A \textit{world} is a model of $T \cup R$ where $T$ is a total choice and $R$ the set of rules of a program.
The semantics is only defined for \textit{sound} programs~\cite{riguzzi2013well} \ie, programs for which each possible total choice $T$ leads to a well-founded model that is two-valued or \textit{total}.
The probability of a possible world that is a model of the program is the probability of the total choice.
Otherwise the probability is $0$~\cite{riguzzi2013well,van1991well}.

Another system, based on Markov Logic~\cite{richardson2006markov}, is \lpmln~\cite{lee2016weighted,lee2017lpmln}, whose models result from \textit{weighted rules} of the form $a \clause b \wedge n$ where $a$ is disjunction of atoms, $b$ is conjunction of atoms and $n$ is constructed from atoms using conjunction, disjunction and negation.
For each model there is a unique maximal set of rules that are satisfied by it and the respective weights determine the weight of that model, that can be normalized to a probability.

\subsection*{Towards Propagating Weights from Total Choices to Events}
\label{ssec:propagating.weights}

The program $\SBF$ in \cref{eq:fruitful} from \cref{ex:fruitful} showcases the problem of propagating weights from \aclp{TC} to \aclp{SM} and then to events.
The main issue arises from the lack of information in the program on how to assign \emph{un-biased} weights to the \aclp{SM}.
This becomes crucial in situations where multiple \aclp{SM} result from a single \acl{TC}.

Our \cref{asp:system.representation.data,asp:sensor.representation.events,asp:wasp.represent.systems} enunciate that a \ac{WASP} program represents a \emph{system}; the \emph{states} of that system, which are partially observable and stochastic, are associated to the program's \aclp{SM}; and state \emph{observations} are encoded as events, \ie\ sets of atoms of the program. 
Then:
\begin{enumerate}

	\item With a weight set for the \aclp{SM}, we extend it to any event in the program domain.

	\item In the case where some statistical knowledge is available, for example, in the form of a distribution relating some atoms, we consider it as `external' knowledge about the parameters, that doesn't affect the propagation procedure described below.

	\item However, that knowledge can be used to estimate the parameters $\theta_{s,t}$ and to `score' the program.

	\item\label{item:program.selection} In that case, if a program is but one of many possible candidates, then that score can be used, \eg\ as fitness, by algorithms searching (optimal) programs of a dataset of events.

	\item If events are not consistent with the program, then we ought to conclude that the program is wrong and must be changed accordingly.

\end{enumerate}

Next, we address the problem of propagating a weight, possibly using parameters (\ie\ algebraic variables) such as $\theta$ in \cref{ex:fruitful}, defined on the \aclp{SM} of a program, $\pwM: \MODELset \to \mathbb{R}$, to the events of that program: $\pwE: \EVENTSset \to \mathbb{R}$.
The latter function can then be normalized and set a probability $\prE:\powerset{\EVENTSset} \to \intcc{0,1}$.
This way probabilistic reasoning is consistent with the \ac{ASP} program and follows our interpretation of \aclp{SM} as the states of an observable system.

\section{Propagating Weights}
\label{sec:propagating.weights}
\begin{figure}[t]
	\begin{center}
		\begin{tikzpicture}[node distance=2em]
			\node[event] (E) {$\emptyevent$};
			\node[event, above = of E] (c) {$c$};
			\node[tchoice, left = of c] (a) {$a$};
			\node[event, left = of a] (b) {$b$};
			\node[right = of c] (invis) {};
			\node[smodel, above = of b] (ab) {$ab$};
			\node[smodel, above = of c] (ac) {$ac$};
			\node[event, above right = of ab] (abc) {$abc$};
			\node[event, above left = of ab] (abC) {$\co{c}ab$};
			\node[event, above right = of ac] (aBc) {$\co{b}ac$};
			\node[indep, right = of ac] (bc) {$bc$};
			\node[tchoice, smodel, right = of invis] (A) {$\co{a}$};
			\node[event, right = of bc] (Ac) {$\co{a}c$};
			\node[event, right = of aBc] (Abc) {$\co{a}bc$};
			% ----
			\draw[doubt] (a) to[bend left] (ab);
			\draw[doubt] (a) to[bend right] (ac);

			\draw[doubt] (ab) to[bend left] (abc);
			\draw[doubt] (ab) to[bend right] (abC);

			\draw[doubt] (ac) to[bend right] (abc);
			\draw[doubt] (ac) to[bend left] (aBc);

			\draw[doubt, dashed] (Ac) to (Abc);

			\draw[doubt] (A) to (Ac);
			\draw[doubt] (A) to[bend right=60] (Abc);

			\draw[doubt] (ab) to[bend right] (E);
			\draw[doubt] (ac) to[bend left=45] (E);
			\draw[doubt] (A) to[bend left] (E);

			\draw[doubt] (ab) to (b);
			\draw[doubt] (ac) to (c);
			\draw[doubt, dashed] (c) to[bend right] (bc);
			\draw[doubt, dashed] (abc) to[bend left] (bc);
			\draw[doubt, dashed] (bc) to (Abc);
			\draw[doubt, dashed] (c) to[bend right] (Ac);
		\end{tikzpicture}
	\end{center}

	\caption{%
		This (partial sub-/super-set) diagram shows some events related to the \aclp{SM} of the program $\SBF$.
		The circle nodes are \aclp{TC} and shaded nodes are \aclp{SM}.
		Solid lines represent relations with the \aclp{SM} and dashed lines some sub-/super-set relations with other events.
		The set of events contained in all \aclp{SM}, denoted by $\consequenceclass$, is $\set{ \emptyevent }$ in this example, because $\co{a} \cap ab \cap ac = \emptyset = \emptyevent$.}
	\label{fig:ex:fruitful}
\end{figure}

The diagram in \cref{fig:ex:fruitful} illustrates the problem of propagating weights from \aclp{TC} to \aclp{SM} and then to general events in an \emph{edge-wise} process, \ie\ where the value in a node is defined from the values in its neighbors.
This quickly leads to interpretation issues concerning weight, with no clear systematic approach.
For example, notice that $bc$ is not directly related with any \acl{SM}.
Propagating values through edges would assign a value ($\not= 0$) to $bc$ hard to explain in terms of the semantics of the program.
Instead, we propose to settle such propagation on the relation an event has with the \aclp{SM}.

\subsection{An Equivalence Relation}
\label{subsec:equivalence.relation}
\begin{figure}[t]
	\begin{center}
		\begin{tikzpicture}[node distance=2em]
			\node[event] (E) {$\emptyevent$};
			\node[event, above = of E] (c) {$c$};
			\node[tchoice, left = of c] (a) {$a$};
			\node[event, left = of a] (b) {$b$};
			\node[right = of c] (invis) {};
			\node[smodel, above = of b] (ab) {$ab$};
			\node[smodel, above = of c] (ac) {$ac$};
			\node[event, above right = of ab] (abc) {$abc$};
			\node[event, above left = of ab] (abC) {$\co{c}ab$};
			\node[event, above right = of ac] (aBc) {$\co{b}ac$};
			\node[indep, right = of ac] (bc) {$bc$};
			\node[tchoice, smodel, right = of invis] (A) {$\co{a}$};
			\node[event, right = of bc] (Ac) {$\co{a}c$};
			\node[event, right = of aBc] (Abc) {$\co{a}bc$};
			% ----
			\path[draw, rounded corners, pattern=north west lines, opacity=0.2]
			(ab.west) -- (ab.north west) --
			(abC.south west) -- (abC.north west) -- (abC.north) --
			(abc.north east) -- (abc.east) -- (abc.south east) --
			(ab.north east) -- (ab.east) -- (ab.south east) --
			(a.north east) --
			(E.north east) -- (E.east) --
			(E.south east) -- (E.south) --
			(E.south west) --
			(b.south west) --
			(ab.west) ;
			% ----
			\path[draw, rounded corners, pattern=north east lines, opacity=0.2]
			(ac.south west) -- (ac.west) -- (ac.north west) --
			(abc.south west) -- (abc.west) -- (abc.north west) --
			(aBc.north east) -- (aBc.east) -- (aBc.south east) --
			(ac.north east) --
			(c.east) --
			(E.east) -- (E.south east) -- (E.south) -- (E.south west) --
			(a.south west) -- (a.west) -- (a.north west) -- (a.north) --
			(ac.south west) ;
			% ----
			\path[draw, rounded corners, pattern=vertical lines, opacity=0.2]
			(Ac.west) --
			(Abc.north west) -- (Abc.north) --
			(Abc.north east) -- (Abc.south east) --
			(Ac.north east) -- (Ac.south east) --
			(A.east) -- (A.south east) --
			(E.south east) -- (E.south) --
			(E.south west) -- (E.west) --
			(E.north west) --
			(Ac.south west) -- (Ac.west);
		\end{tikzpicture}
	\end{center}

	\caption{%
		Classes of (consistent) events related to the \aclp{SM} of $\SBF$ are defined through sub-/super-set relations. 
		%
		In this picture we can see, for example, that $\set{\co{c}ab, ab, b}$ and $\set{a, abc}$ are part of different classes, represented by different fillings.
		%
		As before, the circle nodes are \aclp{TC} and shaded nodes are \aclp{SM}.
		%
		Notice that $bc$ is not in a filled area.}
	\label{fig:ex:fruitful.classes}
\end{figure}

\begin{figure}[t]
	\begin{center}
		\begin{tikzpicture}[3d view]
			\node[event] (INDEPENDENT) at (0,0,0){$\indepclass$};
			\node[smodel] (A) at (0,0,2) {$\co{a}$};
			\node[smodel] (ab) at (3,0,0) {$ab$};
			\node[smodel] (ac) at (0,3,0) {$ac$};
			\node[event] (Aab) at (3,0,2) {$\co{a},ab$};
			\node[event] (Aac) at (0,3,2) {$\co{a},ac$};
			\node[event] (abac) at (3,3,0) {$ab,ac$};
			\node[event] (Aabac) at (3,3,2) {$\consequenceclass$};
			\node[event] (INCONSISTENT) at (-4, 0, 2) {$\inconsistent$
				(inconsistent)};
			% ----
			\draw[->] (INDEPENDENT) -- (A);
			\draw[->] (INDEPENDENT) -- (ab);
			\draw[->] (INDEPENDENT) -- (ac);
			\draw[->] (A) -- (Aab);
			\draw[->] (A) -- (Aac);
			\draw[->] (ab) -- (Aab);
			\draw[->] (ab) -- (abac);
			\draw[->] (ac) -- (Aac);
			\draw[->] (ac) -- (abac);
			\draw[->] (Aab) -- (Aabac);
			\draw[->] (Aac) -- (Aabac);
			\draw[->] (abac) -- (Aabac);
		\end{tikzpicture}
	\end{center}

	\caption{%
		Lattice of the \aclp{SC} from \cref{ex:fruitful}.
		In this diagram the nodes are the different \aclp{SC} that result from the \aclp{SM}, plus the \emph{inconsistent} class ($\inconsistent$).
		The bottom node ($\indepclass$) is the class of \emph{independent} events, those that have no sub-/super-set relation with any \ac{SM} and the top node ($\consequenceclass$) represents events related with all the \acp{SM} \ie\ the \emph{consequences} of the program.
		As in previous diagrams, shaded nodes represent the \acp{SM}.}
	\label{fig:fruitful.lattice}
\end{figure}

Our path to propagate weights starts with the perspective that \aclp{SM} play a role similar to \emph{prime factors} or \emph{principal ideals}.
The \aclp{SM} of a program play a role akin to `irreducible events' entailed from that program and any event must be considered under its relation with the \aclp{SM}.

From \cref{ex:fruitful} (\ie\ $\SBF$) and \cref{fig:ex:fruitful.classes} consider the \aclp{SM} $\co{a}, ab, ac$ and events $a, abc$ and $c$.
While $a$ is related with (i.e.~contained in) both $ab, ac$, the event $c$ is related only with $ac$.
So, $a$ and $c$ are \emph{related with different sets of \aclp{SM}.}
On the other hand, $abc$ contains both $ab, ac$.
Therefore $a$ and $abc$ are \emph{related with the same set of \aclp{SM}.}
We proceed to formalize this relation.

The \textit{\acf{SC}} of the event $e\in \EVENTSset$ is\defnote{$\stablecore{e}$}
\begin{equation}
	\stablecore{e} := \set{\, s \in \MODELset \given s \subseteq e \vee e \subseteq s\, } \label{eq:stable.core}
\end{equation}
where $\MODELset$ is the set of \aclp{SM}.

Notice that the minimality of \aclp{SM} implies that either $e$ is a \acl{SM} or at least one of $\exists s \del{s \subseteq e}, \exists s \del{e \subseteq s}$ is false \emph{i.e.,}\ no \acl{SM} contains another.

\ifExamples
	\begin{example}[Stable cores.]
		\label{ex:stable.cores}
		\em

		Continuing \cref{ex:fruitful}, depicted in
		\cref{fig:ex:fruitful,fig:ex:fruitful.classes,fig:fruitful.lattice}, and
		$\MODELset = \set{ab, ac, \co{a}}$, consider the following \aclp{SC} of some
		events:
		\begin{equation*}
			\begin{aligned}
				\stablecore{a}           & = \set{s \in \MODELset \given s \subseteq a \vee a \subseteq s}                                        & = \set{ab, ac}      %
				\\
				\stablecore{abc}         & = \set{s \in \MODELset \given s \subseteq abc \vee abc \subseteq s}                                    & = \set{ab, ac}      %
				\\
				\stablecore{\co{c}ab}    & = \set{s \in \MODELset \given s \subseteq \co{c}ab \vee \co{c}ab \subseteq s}                          & = \set{ab}          %
				\\
				\stablecore{bc}          & = \set{s \in \MODELset \given s \subseteq bc \vee bc \subseteq s}                                      & = \emptyset         %
				\\
				\stablecore{\emptyevent} & = \set{s \in \MODELset \given s \subseteq \emptyset \vee \emptyset \subseteq s} = \set{ab, ac, \co{a}} & = \consequenceclass %
				\\
			\end{aligned}
		\end{equation*}

		Events $a$ and $abc$ have the same \ac{SC}, while $\co{c}ab$ has a different
		\ac{SC}.
Also, $bc$ is \emph{independent of} (\emph{i.e.}\ not related to)
		any \acl{SM}.
Since events are sets of literals, the empty set is an event
		and a subset of any \ac{SM}.
	\end{example}
\fi

We now define an equivalence relation so that two events are related if either both are inconsistent or both are consistent and, in the latter case, with the same \acl{SC}.
\begin{definition}[Equivalence Relation on Events]\label{def:equiv.rel}

	For a given program, let $u, v \in \EVENTSset$.
	The equivalence relation\defnote{$\sim$}
	$u \sim v$ is defined by
	\begin{equation}
		u,v \not\in\CONSISTset \vee \del{u,v \in \CONSISTset \wedge \stablecore{u} = \stablecore{v}}.\label{eq:equiv.rel}
	\end{equation}

\end{definition}

This equivalence relation defines a partition on the set of events, where each class holds a unique relation with the \aclp{SM}.
In particular we denote each class by:\defnote{$\class{e}$}
\begin{equation}
	\class{e} =
	\begin{cases}
		\inconsistent := \EVENTSset \setminus \CONSISTset
		 & \text{if~} e \in \EVENTSset \setminus \CONSISTset, %
		\\
		\set{u \in \CONSISTset \given \stablecore{u} = \stablecore{e}}
		 & \text{if~} e \in \CONSISTset.
	\end{cases}\label{eq:event.class}
\end{equation}
where $\inconsistent$ denotes the set $\EVENTSset\setminus\CONSISTset$ of \emph{inconsistent} events, \ie\ events that contain $\set{x,\co{x}}$ for some atom $x$.\defnote{$\inconsistent$}

\begin{proposition}[Class of the Program's Consequences]
	\label{prop:consequence.class}
	\defnote{$\emptyevent,\consequenceclass$}
	Let $\emptyevent$ be the empty set event (notice that $\emptyevent = \emptyset \in \EVENTSset$)
	\footnote{We adopt the notation `$\emptyevent$' for \emph{empty word}, from formal languages, to distinguish `$\emptyset \in \EVENTSset$' from `$\emptyset \subset\EVENTSset$'.}, and $\consequenceclass$ the \emph{consequence class} of (consistent) events related with all the
	\aclp{SM}.
	Then
	\sidenote{Removed `$=\stablecore{\MODELset}$' from this equation.}
	\begin{equation}
		\class{\emptyevent} = \consequenceclass.
	\end{equation}
\end{proposition}
\begin{proof}
	Let $x \in \class{\emptyevent}$ be consistent.
	Then $x \sim \lambda$. Since $\stablecore{\emptyevent} = \MODELset$ also $\stablecore{x} = \MODELset$. Hence  $x\in\consequenceclass$.

	Now, let $x \in \consequenceclass$. So $x$ is consistent and, for each $s \in \MODELset$, either $s \subseteq x$ or $s \supseteq x$. So, $\stablecore{x} = \MODELset = \stablecore{\emptyevent}$. By \cref{def:equiv.rel}, $x \sim \emptyevent$ \ie\ $x \in \class{\emptyevent}$.
	\hfill
\end{proof}

The combinations of \aclp{SM}, \ie~the \aclp{SC}, together with the set of inconsistent events ($\inconsistent$) forms a set of representatives for the equivalence relation $\sim$.
Since all events within a consistent equivalence class have the same \acl{SC}, we are interested in functions (including weight assignments), that are constant within classes.
A function $f:\EVENTSset\to Y$, where $Y$ is any set, is said to be \emph{coherent} if
\begin{equation}
	\forall e\in \EVENTSset~\forall u\in \class{e} \left( f\at{u} = f\at{e} \right).
\end{equation}

Considering coherent functions, in the specific case of \cref{eq:fruitful}, instead of dealing with the $2^6 = 64$ events, we need to consider only the
$2^3 + 1 = 9$ classes, well defined in terms of combinations of the \aclp{SM}, to define coherent functions.
In general, a program with $n$ atoms and $m$ \aclp{SM} has $2^{2n}$ events and $2^m + 1$ \aclp{SC} --- but easily $m \gg n$.

\ifExamples
	\begin{example}[Events classes.]\label{ex:classes}\em

		Consider again \cref{ex:fruitful}.
As previously stated, the \aclp{SM} are
		the elements of $\MODELset = \set{\co{a}, ab, ac}$ so the quotient set of
		this relation is
		\begin{equation*}
			\class{\EVENTSset} = \set{
				\begin{array}{lll}
					\inconsistent,           &
					\indepclass,             &
					\stablecore{\co{a}},%
					\\
					\stablecore{ab},         &
					\stablecore{ac},         &
					\stablecore{\co{a}, ab},%
					\\
					\stablecore{\co{a}, ac}, &
					\stablecore{ab, ac},     &
					\consequenceclass
				\end{array}
			},
		\end{equation*}
		where $\indepclass$ denotes the class of \emph{independent
			events} $e$ such that $\stablecore{e} = \set{\emptyset}$,
		while $\consequenceclass = \stablecore{\MODELset}$ is the set of
		events related with all \acp{SM}.
We have:
		\begin{equation*}
			\begin{array}{l|lr}
				\stablecore{e}
				       & \class{e}
				       & \# \class{e}                                                                           %
				\\
				\hline
				%
				\inconsistent
				       & \co{a}a, \ldots
				       & 37                                                                                     %
				\\
				%
				\indepclass
				       & \co{b}, \co{c}, bc, \co{b}a, \co{b}c, \co{bc}, \co{c}a, \co{c}b, \co{bc}a
				       & 9                                                                                      %
				\\
				%
				\co{a}
				       & \co{a}, \co{a}b, \co{a}c, \co{ab}, \co{ac}, \co{a}bc, \co{ac}b, \co{ab}c, \co{abc}
				       & 9                                                                                      %
				\\
				%
				ab     & b, ab, \co{c}ab                                                                    & 3 \\%%
				%
				ac     & c, ac, \co{b}ac                                                                    & 3 \\%%
				%
				\co{a}, ab
				       &
				       & 0                                                                                      %
				\\
				%
				\co{a}, ac
				       &
				       & 0
				%
				\\
				%
				ab, ac & a, abc                                                                             & 2 \\%%
				%
				\consequenceclass
				       & \emptyevent
				       & 1
				\\
				%
				\hline \class{\EVENTSset}
				       & \EVENTSset
				       & 64
			\end{array}
		\end{equation*}

		Notice that $bc \in \indepclass$, as hinted by
		\cref{fig:ex:fruitful,fig:ex:fruitful.classes}.
	\end{example}
\fi

\subsection{From Total Choices to Events}
\label{subsec:from.tchoices.to.events}

The `propagation' phase, traced by \cref{eq:weight.total.choice} and \crefrange{eq:weight.stablemodel}{eq:weight.events.unconditional}, starts with the weight of \aclp{TC}, $\wgtT\at{t}$, propagates it to the \aclp{SM}, $\wgtm{s}$, and then, within the equivalence relation from \cref{eq:equiv.rel}, to a coherent weight of events,
$\wgte{e}$.
So we are specifying a sequence of functions
\begin{equation}
	\wgtT \longrightarrow \wgtM \longrightarrow \wgtC \longrightarrow \wgtE\label{eq:sequence.functions}
\end{equation}
on successive larger domains
$$
\TCHOICEset \longrightarrow \MODELset \longrightarrow \class{\EVENTSset} \longrightarrow \EVENTSset
$$
such that the last function ($\wgtE$) is a finite coherent function on the set of events and thus, as a final step, it can easily be used to define a probability distribution of events by normalization:
\(
\wgtE \longrightarrow \prE
\).

\subsubsection*{\Aclp{TC} and \Aclp{SM}}
\label{par:prop.totalchoices}

Let's start by looking into the first two steps of the sequence of functions \cref{eq:sequence.functions}: $\wgtT$ and $\wgtM$.

The weight $\wgtT$ of the \acl{TC} $t \in \TCHOICEset$ is already given by \cref{eq:weight.total.choice}.

Recall that each \acl{TC} $t \in \TCHOICEset$, together with the rules and the other facts of a program, defines the set \tcgen{t} of \aclp{SM} associated with that choice.
Given a \acl{TC} $t \in \TCHOICEset$, a \acl{SM}
$s \in \MODELset $, and formal variables or values $\theta_{s,t} \in
	\intcc{0, 1}$ such that $\sum_{s\in \tcgen{t}} \theta_{s,t} = 1$, we define\defnote{$\wgtm{s,t}$}
\begin{equation}
	\wgtm{s, t} := \begin{cases}
		              \theta_{s,t} & \text{if~} s \in \tcgen{t}\cr 0 & \text{otherwise.}
	              \end{cases}
	\label{eq:weight.stablemodel}
\end{equation}

The $\theta_{s,t}$ parameters in \cref{eq:weight.stablemodel} express the \emph{program's} lack of information about the weight assignment, when a single \acl{TC} entails more than one \acl{SM}.
We address this issue by assigning a possibly unknown parameter, \ie~a formal algebraic variable ($\theta_{s,t}$) associated with a \acl{TC} ($t$) and a \acl{SM} ($s$).
This allows the expression of a quantity that does not result from the program's syntax but can be determined or estimated given more information, \eg\ observed data.

As sets, two \aclp{SM} can have non-empty intersection.
But because different \acp{SM} represent different states of a system ---which are \emph{disjoint events}--- we assume that the algebra of the \aclp{SM} is $\sigma$-additive
%\sidenote{\franc{highlight this}}:

\begin{assumption}[\Aclp{SM} as Disjoint events]
	\label{assumption:smodels.disjoint}%

	For any set $X$ of \aclp{SM} and any \acl{TC} $t$,
	\begin{equation}
		\wgtM\at{X, t} = \sum_{s\in X}\wgtM\at{s, t}.\label{eq:smodels.disjoint}
	\end{equation}

\end{assumption}

\Cref{eq:smodels.disjoint} is the basis for \cref{eq:weight.class.consistent} and effectively extends $\wgtM:\MODELset \times \TCHOICEset \to \mathbb{R}$ to $\wgtM:\powerset{\MODELset} \times \TCHOICEset \to \mathbb{R}$.
Now the pre-condition of \cref{eq:weight.stablemodel} can be stated as $\wgtM\at{\MODELset\at{t}, t} = 1$.

\ifExamples
	\begin{example}[\Aclp{SM} and parameters.]
		\label{ex:models.parameters}
		\em

		The program from \cref{ex:fruitful} has no information about the
		probabilities of the \aclp{SM} that result from the \acl{TC} $t = \set{a}$.
		These models are $\MODELset\at{\set{a}} = \set{ab, ac}$ so we need two
		parameters $\theta_{ab, \set{a}}, \theta_{ac, \set{a}} \in \intcc{0,1}$ and
		such that (\textit{cf.}\ \cref{eq:weight.stablemodel})
		\begin{equation*}
			\theta_{ab, \set{a}} + \theta_{ac, \set{a}} = 1.
		\end{equation*}

		If we let $\theta = \theta_{ab, \set{a}}$ then
		\begin{equation*}
			\theta_{ac, \set{a}} = 1 - \theta = \co{\theta}.
		\end{equation*}

		Also
		\begin{equation*}
			\begin{split}
				\theta_{ab, \set{\co{a}}} & = 0, %
				\\
				\theta_{ac, \set{\co{a}}} & = 0
			\end{split}
		\end{equation*}
		because $ab, ac \not\in\MODELset\at{\co{a}}$.
	\end{example}
\fi

\subsubsection*{Classes}
\label{par:prop.class.cases}

Consider the next step in sequence \cref{eq:sequence.functions}, the function $\wgtC$
on $\class{\EVENTSset}$.
Each class of the equivalence relation $\sim$ (eq.~\ref{eq:equiv.rel}) is either the inconsistent class ($\inconsistent$) or is associated with a \acl{SC}, \textit{i.e.~}a set of \aclp{SM}.
Therefore, $\wgtC$ is defined considering the following two cases:\defnote{$\wgtC$}
\paragraph{Inconsistent class.} This class contains events that are (classically) inconsistent, thus should never be observed and thus have weight zero:
\begin{equation}
	\wgtc{\inconsistent, t} := 0.
	\footnote{This weight being zero is independent of the \aclp{SM}.}
	\label{eq:weight.class.inconsistent}
\end{equation}
\paragraph{Consistent classes.} For the propagation function to be coherent, it must be constant within a class and its value dependent only on the \acl{SC}:
\begin{subequations}
	\begin{equation}
		\wgtc{\class{e}, t} := \wgtm{\stablecore{e}, t} = \sum_{s\in\stablecore{e}}\wgtm{s, t}.
		\label{eq:weight.class.consistent}
	\end{equation}
	and we further define the following:
	\begin{equation}
		\wgtc{\class{e}} := \sum_{t \in \TCHOICEset} \wgtt{t}\wgtc{\class{e}, t}
		\label{eq:weight.class.unconditional}
	\end{equation}
\end{subequations}
\Cref{eq:weight.class.consistent} states that the weight of a class $\class{e}$ is the weight of its \acl{SC}
($\stablecore{e}$) and \cref{eq:weight.class.unconditional}
\emph{averages} \cref{eq:weight.class.consistent} over the \aclp{TC}.
%
Notice that \cref{eq:weight.class.consistent} also applies to the independent class, $\indepclass = \set{ e \given \stablecore{e} = \emptyset}$, because events in this class are not related with any \acl{SM}:\defnote{$\indepclass$}
\begin{equation}
	\wgtc{\indepclass, t} = \sum_{s\in\emptyset}\wgtm{s, t} = 0.
	\label{eq:weight.class.independent}
\end{equation}

\ifExamples
	\begin{example}[Weight of \aclp{SM} and classes.]\label{ex:weights.sm}\em
		\begin{equation*}
			\begin{array}{c||l|ccc|ccc|c|c|r}
				%=====================================================
				  &
				A & B                                         & C      & D           & E & F & G & H & I & J
				\\[3pt]
				\hline
				\hline
				\multirow{3}{*}{\phantom{2em}}
				  & \multirow{3}{*}{\stablecore{e}}
				  & \multicolumn{3}{c|}{\wgtm{s,\set{\co{a}}}}
				  & \multicolumn{3}{c|}{\wgtm{s,\set{a}}}
				  & \wgtc{\class{e},\set{\co{a}}}
				  & \wgtc{\class{e},\set{a}}
				  & \multirow{3}{*}{\wgtc{\class{e}}}
				\\[2pt]
				%=====================================================
				  &
				  & \co{a}                                    & ab     & ac
				  & \co{a}                                    & ab     & ac
				  & \pwt{\set{\co{a}}}
				  & \pwt{\set{a}}
				  &
				\\[2pt]
				%=====================================================
				  &
				  & 1                                         & 0      & 0
				  & 0                                         & \theta & \co{\theta}
				  & 0.7
				  & 0.3
				  &
				\\[3pt]
				%=====================================================
				\hline
				1
				  & \co{a}
				  & 1                                         &        &
				  & 0                                         &        &
				  & 1
				  & 0
				  & 0.7
				\\[2pt]
				%=====================================================
				2
				  & ab
				  &                                           & 0      &
				  &                                           & \theta &
				  & 0
				  & \theta
				  & 0.3\theta
				\\[2pt]
				%=====================================================
				3
				  & ac
				  &                                           &        & 0
				  &                                           &        & \co{\theta}
				  & 0
				  & \co{\theta}
				  & 0.3\co{\theta}
				\\[2pt]
				%=====================================================
				4
				  & \co{a}, ab
				  & 1                                         & 0      &
				  & 0                                         & \theta &
				  & 1
				  & \theta
				  & 0.7 + 0.3\theta
				\\[2pt]
				%=====================================================
				5
				  & \co{a}, ac
				  & 1                                         &        & 0
				  & 0                                         &        & \co{\theta}
				  & 1
				  & \co{\theta}
				  & 0.7 + 0.3\co{\theta}
				\\[2pt]
				%=====================================================
				6
				  & ab, ac
				  &                                           & 0      & 0
				  &                                           & \theta & \co{\theta}
				  & 0
				  & \theta + \co{\theta} = 1
				  & 0.3
				\\[2pt]
				%=====================================================
				7
				  & \consequenceclass
				  & 1                                         & 0      & 0
				  & 0                                         & \theta & \co{\theta}
				  & 1
				  & \theta + \co{\theta} = 1
				  & 1
				%=====================================================
			\end{array}
		\end{equation*}

		Continuing \cref{ex:fruitful}, we show the propagation of $\pwT$ to $\pwM$
		(\cref{eq:weight.tchoice}) and then to $\wgtC$
		(\cref{eq:weight.class.consistent,eq:weight.class.unconditional}).
The
		table above resumes the calculations to compute $\wgtc{\class{e}}$ for each $e
			\in \EVENTSset$.
For example, $e = abc$ the calculation of $J6 =
			\wgtc{\class{abc}}$ follows these steps:
		\begin{enumerate}
			\item $\stablecore{abc} = \set{ab,ac}$ --- is in line $6$ of the table.
			\item Since $\TCHOICEset = \set{\set{a}, \set{\co{a}}}$, we need to calculate $I6 =
				      \wgtc{\class{abc}, \set{a}}$ and $H6 = \wgtc{\class{abc}, \set{\co{a}}}$.
By
			      \cref{eq:weight.class.consistent}:
			      \begin{equation*}
				      \begin{aligned}
					      H6 = \wgtc{\class{abc}, \set{\co{a}}}
					       & = \sum_{s \in \stablecore{abc}} \wgtm{s, \set{\co{a}}}
					      =
					       & \wgtm{ab, \set{\co{a}}} +  \wgtm{ac, \set{\co{a}}}      %
					      \\
					      I6 = \wgtc{\class{abc}, \set{a}}
					       & = \sum_{s \in \stablecore{abc}} \wgtm{s, \set{a}}
					      =
					       & \wgtm{ab, \set{a}} +  \wgtm{ac, \set{a}}
				      \end{aligned}
			      \end{equation*}
			\item The $\wgtm{s,t}$ above result from \cref{eq:weight.stablemodel} --- the
			      non-empty cells in columns $B:D$ and $E:G$:
			      \begin{equation*}
				      \begin{aligned}
					      C6
					       & = \wgtm{ab, \set{\co{a}}}
					       & = 0                      %
					      \\
					      D6
					       & = \wgtm{ac, \set{\co{a}}}
					       & = 0                      %
					      \\
					      F6
					       & = \wgtm{ab, \set{a}}
					       & = \theta                 %
					      \\
					      G6
					       & = \wgtm{ac, \set{a}}
					       & = \co{\theta}
				      \end{aligned}
			      \end{equation*}
			\item So we have --- columns $H, I$:
			      \begin{equation*}
				      \begin{aligned}
					      H6
					       & = \wgtc{\class{abc}, \set{\co{a}}}
					       & = 0 + 0
					       &
					       & = 0                               %
					      \\
					      I6
					       & = \wgtc{\class{abc}, \set{a}}
					       & = \theta + \co{\theta}
					       &
					       & = 1
				      \end{aligned}
			      \end{equation*}
			\item At last, by \cref{eq:weight.class.unconditional} --- columns $H, I$ and $J$:
			      \begin{equation*}
				      \begin{split}
					      J6 = \wgtc{\class{abc}}
					       & = \sum_{t\in\MODELset} \wgtc{\class{abc}, t}\pwt{t}                %
					      \\
					       & =  \wgtc{\class{abc}, \set{\co{a}}}\pwt{\set{\co{a}}} +
					      \wgtc{\class{abc}, \set{a}}\pwt{\set{a}}%
					      \\
					       & =  0 \co{\theta} +  1 \theta =  0 \times 0.7 +  1\times 0.3 = 0.3
				      \end{split}
			      \end{equation*}
		\end{enumerate}
	\end{example}
\fi

\subsubsection*{Events and Probability}
\label{par:propagation.event.cases}

Each consistent event $e \in \EVENTSset$ is in the class defined by its
\acl{SC} $\stablecore{e}$.
So, denoting the number of elements in $X$ as $\#
	X$, we set:\defnote{$\wgtE$}
\begin{subequations}
	\begin{equation}
		\wgte{e, t} :=
		\begin{cases}
			\frac{\wgtc{\class{e}, t}}{\# \class{e}} & \text{if~}\# \class{e} > 0, %
			\\
			0                                       & \text{otherwise}.
		\end{cases}
		\label{eq:weight.events}
	\end{equation}
	and, by averaging over the \aclp{TC}:
	\begin{equation}
		\wgte{e} := \sum_{t\in\TCHOICEset} \wgtt{t}\wgte{e, t}.
		\label{eq:weight.events.unconditional}
	\end{equation}
\end{subequations}

The \cref{eq:weight.events.unconditional} is the main goal of this paper: propagate the weights associated to facts of an \ac{WASP} to the set of all events of that program.
%
In order to get a probability from \cref{eq:weight.events.unconditional}, concerning the \emph{Probabilistic Tasks} goal, we define the \emph{normalizing factor}:
\begin{equation}
	Z :=
	\sum_{e \in \EVENTSset} \wgte{e} =
	\sum_{\class{e} \in \class{\EVENTSset}} \wgtc{\class{e}},\label{eq:normalizing.factor}
\end{equation}
and now \cref{eq:weight.events.unconditional} provides a straightforward way to define the \emph{probability of a single event $e \in \EVENTSset$}:\defnote{$\prE$}
\begin{equation}
	\prE\at{e} := \frac{\wgte{e}}{Z}.\label{eq:probability.event}
\end{equation}

\Cref{eq:probability.event} defines a coherent \emph{prior}\footnote{In the Bayesian sense that future observations might update this probability.} probability of events and, together with external statistical knowledge, can be used to learn about the \emph{initial} probabilities of the atoms.

\paragraph{The effect of propagation.} One way to assess the effect of propagating weights through the \acp{SM} to the events is to compare $\prE$ with a `probability' induced syntactically from the weights of facts. It is sufficient to consider what appens with the \aclp{TC}: if we syntactically induce a probability for the \acp{TC}, say $\prT$, is it true that $\prE\at{t} = \prT\at{t}$ for all $t \in \TCHOICEset$?

The weight assignment of the \aclp{TC} can also be normalized into a probability distribution. 
For $t\in\TCHOICEset$,\defnote{$\prT$}
\begin{equation}
	\prT\at{t} = \frac{\wgtt{t}}{\sum_{\tau \in \TCHOICEset} \wgtt{\tau}}
	\label{eq:syntactic.probability.totalchoices}
\end{equation}

And now we ask if these probabilities coincide in $\TCHOICEset$:

$$
\forall t \in \TCHOICEset \del{\prE\at{t} = \prT\at{t}}?
$$

It is easy to see that, in general, this cannot be true.
While the domain of $\prT$ is the set of \aclp{TC}, for $\prE$ the domain is much larger, including all the events.
Except for trivial programs, some events other than \aclp{TC} will have non-zero weight.


\begin{proposition}[Two Distributions] \label{prop:two.distributions} %

	If a program has a consistent event $e \in \CONSISTset\setminus\TCHOICEset$ such that $\prE\at{e} \not= 0$ then there is at least one $t\in\TCHOICEset$ such that
	\begin{equation}
		\prT\at{t} \not= \prE\at{t}. \label{eq:two.distributions}
	\end{equation}

\end{proposition}
\begin{proof}
	Suppose towards a contradiction that $\prT\at{t} = \prE\at{t}$ for
	all $t \in \TCHOICEset$ and $\eta$ as above.

	Then
	\begin{equation*}
		1 = \sum_{t \in \TCHOICEset} \prT\at{t}  = \sum_{t \in \TCHOICEset} \prE\at{t}.
	\end{equation*}

	Therefore, $\prE\at{\eta} = 0$ for all $\eta \in \CONSISTset\setminus\TCHOICEset$, in contradiction with the hypothesis on $e$.
	\hfill
\end{proof}

The essential, perhaps \emph{counter-intuitive}, conclusion of \cref{prop:two.distributions} is that we are dealing with \emph{two distributions}: $\prT$, restricted to the \aclp{TC}, results \emph{syntactically} from the annotations of the program, while $\prE$, extended to events, results from both the annotations and the program's \emph{semantics}, \ie\ the \aclp{SM}.

For \cref{ex:fruitful}:
\begin{equation*}
	\begin{aligned}
		\prT\at{a} & = 0.3          &  &
		\text{from the program } \SBF, %
		\\
		\prE\at{a} & = \frac{3}{64} &  &
		\text{from \cref{eq:sbf.prior}}.
	\end{aligned}
\end{equation*}

\ifExamples
	\begin{example}[Coherent probability of events.]\label{ex:choerent.probability}\em

		In \cref{ex:weights.sm} we determined $\wgtc{\class{e}, t}$ from
		\cref{eq:weight.class.consistent} and also $\wgtc{\class{e}}$, the weight of
		each class, using \cref{eq:weight.class.unconditional}, that marginalizes
		the \aclp{TC}.
		\begin{equation*}
			\begin{array}{l|cc|c|c}
				\stablecore{e}
				       & \hspace{1em}\wgtC\hspace{1em}
				       & \hspace{1em}\#\class{e}\hspace{1em}
				       & \hspace{1em}\pwE\hspace{1em}
				       & \hspace{1em}\wgtE\hspace{1em}
				\\
				\hline
				%
				\inconsistent
				       & 0
				       & 37
				       & 0
				       & 0
				\\[4pt]
				%
				\indepclass
				       & 0
				       & 9
				       & 0
				       & 0
				\\[4pt]
				%
				\co{a}
				       & \frac{7}{10}
				       & 9
				       & \frac{7}{90}
				       & \frac{7}{207}
				\\[4pt]
				%
				ab     & \frac{3}{10}\theta                  & 3 & \frac{1}{10}\theta      & \frac{1}{23}\theta \\[4pt]
				%
				ac     & \frac{3}{10}\co{\theta}             & 3 & \frac{1}{10}\co{\theta} &
				\frac{1}{23}\co{\theta}                                                                         \\[4pt]
				%
				\co{a}, ab
				       & \frac{7 + 3\theta}{10}
				       & 0
				       & 0
				       & 0
				\\[4pt]
				%
				\co{a}, ac
				       & \frac{7 + 3\co{\theta}}{10}
				       & 0
				       & 0
				       & 0
				\\[4pt]
				%
				ab, ac & \frac{3}{10}                        & 2 & \frac{3}{20}            & \frac{3}{46}       \\[4pt]
				%
				\consequenceclass
				       & 1
				       & 1
				       & 1
				       & \frac{10}{23}
				\\[4pt]
				%
				\hline
				       &
				       &
				       &
				       &
				\\[-0.5em]
				       & Z = \frac{23}{10}
				       &
				       & \frac{\wgtC}{\#\class{e}}
				       & \frac{\pwE}{X}
				%& \Sigma = 1 
			\end{array}
		\end{equation*}

		From there we can follow \cref{eq:weight.events} to calculate the weight
		$\wgte{e, t}$ of each event given $t$, by simply dividing $\wgtc{\class{e}, t}$
		by $\#\class{e}$, the total number of elements in $\class{e}$.
		Then we marginalize $t$ in $\wgte{e, t}$ to get $\wgte{e}$.
		Finally, the normalization factor from \cref{eq:normalizing.factor} and \cref{eq:weight.event} provide a coherent \emph{prior} weight for each event.

		In summary, the coherent \emph{prior} weight of events of program
		\cref{eq:fruitful} is
		\begin{equation}
			\begin{array}{l|ccccccccc}
				\stablecore{e}          &
				\inconsistent           &
				\indepclass             &
				\co{a}                  &
				ab                      &
				ac                      &
				\co{a}, ab              &
				\co{a}, ac              &
				ab, ac                  &
				\consequenceclass
				\\ \hline
				\wgtE\at{e}              &
				0                       &
				0                       &
				\frac{7}{207}           &
				\frac{1}{23}\theta      &
				\frac{1}{23}\co{\theta} &
				0                       &
				0                       &
				\frac{3}{46}            &
				\frac{10}{23}
			\end{array}
		\end{equation}
		\label{eq:sbf.prior}

	\end{example}
\fi

Now $\prE:\EVENTSset \to \intcc{0,1}$ can be extended to
$\prE:\powerset{\EVENTSset}\to\intcc{0,1}$ by abusing notation and setting, for $X \subseteq \EVENTSset$,
\begin{equation}
	\prE\at{X} = \sum_{x\in X}\prE\at{x}.
	\label{eq:prob.event.set}
\end{equation}
It is straightforward to verify that the latter satisfies the Kolmogorov axioms of probability.

We can now properly state the following property about \emph{certain facts}
such as $\weightfact{a}{1.0}$.
\begin{proposition}[Probability of Certain Facts]
	\label{prop:prob.one}

	Consider a program $A$ with the \acl{WF} $\weightfact{a}{1.0}$ and
	$A^{\ast}$ that results from $A$ by replacing that fact by the deterministic fact $a$. Let $\prE$ be as
	\cref{eq:probability.event} for $A$ and $\prfunc^{\ast}_{\EVENTSset}$ for $A^{\ast}$.
	Then
	\begin{equation}
		\forall e \in \EVENTSset \left(\prE\at{e} = \prfunc^{\ast}_{\EVENTSset}\at{e}\right).
	\end{equation}
\end{proposition}
\begin{proof}
	\sidenote{do this}

\hfill
\end{proof}


\begin{example}[Probability of Events]
	\label{ex:prob.events}
	\em
	The coherent \emph{prior} probability of events of program \SBF\ in \cref{ex:fruitful} is
	\begin{equation}
		\begin{array}{l|ccccccccc}
			\stablecore{e}          &
			\inconsistent           &
			\indepclass             &
			\co{a}                  &
			ab                      &
			ac                      &
			\co{a}, ab              &
			\co{a}, ac              &
			ab, ac                  &
			\consequenceclass
			\\ \hline
			\prE\at{e}              &
			0                       &
			0                       &
			\frac{7}{207}           &
			\frac{1}{23}\theta      &
			\frac{1}{23}\co{\theta} &
			0                       &
			0                       &
			\frac{3}{46}            &
			\frac{10}{23}
		\end{array}
		\label{eq:sbf.prior}
	\end{equation}

	This table can be used to compute the probability of any single event $e \in \EVENTSset$ by looking at the column of the event's \acl{SC}.

	For example:
	\begin{list}{\hspace{2em}}{\setlength\itemsep{0.5em}}
		\item $\wgtE\at{ab} = \frac{\theta}{23}, $ because $ab$ is the only \ac{SM} related with $ab$ so $\stablecore{ab} = \set{ab}$ and the weight value is found in the respective column of \cref{eq:sbf.prior}.

		\item $\wgtE\at{abc} = \frac{3}{46}$ because $abc \supset  ab$ and $abc \supset ac$.
		So $\stablecore{abc} = \set{ab, ac}$.

		\item $\wgtE\at{bc} = 0$ because, since there is no \ac{SM} $s$ that either $s \subset bc$ or $bc \subset s$, $\stablecore{bc} = \emptyset$ \emph{i.e.}\ $bc \in \indepclass$.

		\item $\wgtE\at{\co{a}b} = \frac{7}{207}$ because $\stablecore{\co{a}b} = \set{\co{a}}$.

		\item $\wgtE\at{\co{a}} = \frac{7}{207}$ and  $\wgtE\at{a} = \frac{3}{46}$.
		Notice that $\wgtE\at{\co{a}} + \wgtE\at{a} \not= 1$. 
		This highlights the fundamental difference between $\wgtE$ and $\wgtT$ (\emph{cf.~}\cref{prop:two.distributions}), where the former results from the lattice of the \aclp{SC} and the latter directly from the explicit assignment of probabilities to literals.
	\end{list}

	Related with the last case above, consider the complement of a consistent event $e$, denoted by $\complement e$.\defnote{$\complement e$}
	To calculate $\prE\at{\complement e}$ we look for the classes in $\class{\EVENTSset}$ that are not $\class{e}$, \ie~the complement of $e$'s class within $\class{\EVENTSset}$\footnote{All the usual set operations hold on the complement.
	For example, $\complement\complement X = X$.}, $\complement\class{e}$.
	Considering that $\class{\EVENTSset}$ is in a one-to-one correspondence with the \aclp{SC} plus $\inconsistent$, 
	\begin{equation*}
		\class{\EVENTSset} \simeq \set{
			\inconsistent, \indepclass, \set{\co{a}}
			, \set{ab}, \set{ac}, \set{\co{a}, ab}
			, \set{\co{a}, ac}, \set{ab, ac}, \consequenceclass}.
	\end{equation*}
	In particular, for $\wgtE\at{\complement a}$, since $\stablecore{a} = \set{ab, ac}$ then $\complement \class{a} = \class{\EVENTSset} \setminus \class{a}$ and
	\(
	\prE\at{\complement a} =  \prE\at{\class{\EVENTSset} \setminus \class{a}} = 1 - \prE\at{a}
	\).
	Also, $\prE\at{\complement \co{a}} =  1 - \prE\at{\co{a}} $.
\end{example}

While not illustrated in our examples, this method also applies to programs that have more than one \acl{PF}, like
\begin{equation*}
	\left\{
	\begin{aligned}
		\weightfact{a & }{0.3},             %
		&&
		\weightfact{b & }{0.6},             %
		\\
		c \vee d    & \clause a \wedge b.
	\end{aligned}
	\right.
\end{equation*}

Our approach generalizes to Bayesian networks in a way similar to
\cite{cozman2020joy,raedt2016statistical} and
\cite{kiessling1992database,thone1997increased} as follows.
On the one hand, any acyclic propositional program can be viewed as the specification of a Bayesian network over binary random variables.
So, we may take the structure of the Bayesian network to be the dependency graph.
The random variables then correspond to the atoms and the probabilities can be read off of the probabilistic facts and rules.
Conversely, any Bayesian network over binary variables can be specified by an acyclic non-disjunctive \ac{WASP}.

\section{Discussion and Future Work}
\label{sec:discussion}

This work is a first venture into expressing weight assignments using algebraic expressions derived from a logical program, in particular an \ac{ASP}.
We would like to point out that there is still much to explore concerning the full expressive power of logic programs and \ac{ASP} programs.
So far, we have not considered recursion, logical variables or functional symbols.


The theory, methodology, and tools, from Bayesian Networks can be adapted to our approach.
The connection with Markov Fields \cite{kindermann80} is left for future work.
An example of a `program selection' application (as mentioned in \cref{item:program.selection}, \cref{ssec:propagating.weights}) is left for future work.
Also, there is still little effort concerning the \emph{Probabilistic Tasks} and to articulate with the related fields of probabilistic logical programming, machine learning, inductive programming, \emph{etc.}

The equivalence relation from \cref{def:equiv.rel} identifies the $s \subseteq e$ and $e \subseteq s$ cases.
Relations that distinguish such cases might enable better relations between the representations and processes from the \aclp{SM}.

Furthermore, we decided to set the weight of inconsistent events to $0$ but, maybe, in some cases, we shouldn't.
For example, since observations may be affected by noise, one can expect to occur some inconsistencies.

\section*{Acknowledgements}

This work is partly supported by Funda\c{c}\~ao para a Ci\^{e}ncia e Tecnologia (FCT/IP) under contracts UIDB/04516/2020 (NOVA LINCS), UIDP/04674/2020 and UIDB/04675/2020 (CIMA).

The authors are grateful to LÃ­gia Henriques-Rodrigues, Matthias Knorr and Ricardo GonÃ§alves for valuable comments on a preliminary version of this paper, and Alice Martins for contributions on software development.

\ifLNCS \bibliographystyle{splncs04} \fi
\ifTLP%
	\ifTLPBIB
		\bibliographystyle{tlplike}
	\else
		\bibpunct{(}{)}{;}{a}{}{;}
		\bibliographystyle{kluwer}
	\fi
\fi

\bibliography{zugzwang}
\end{document}

